{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM348zMgrp61DE00sXqGXDN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"PKo1T_zVQs7d","executionInfo":{"status":"ok","timestamp":1731315315033,"user_tz":-60,"elapsed":18436,"user":{"displayName":"Mahdi Torkzaban","userId":"15809237820962324254"}}},"outputs":[],"source":["import pandas as pd\n","import statsmodels.api as sm\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load data\n","file_path = 'trainset.xlsx'\n","data = pd.read_excel(file_path)\n","\n"]},{"cell_type":"code","source":["\n","# Separate features and target\n","X = data.drop(columns=['result'])\n","y = data['result']\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n"],"metadata":{"id":"hLbPY9vq3XKb","executionInfo":{"status":"ok","timestamp":1731315315035,"user_tz":-60,"elapsed":14,"user":{"displayName":"Mahdi Torkzaban","userId":"15809237820962324254"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","# Add constant for intercept\n","X = sm.add_constant(X)\n","\n","# Fit logistic regression model using statsmodels\n","logit_model = sm.Logit(y, X)\n","result = logit_model.fit(maxiter=20000)\n","\n","# Display coefficients and p-values\n","print(result.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubxrPwHZzeEV","executionInfo":{"status":"ok","timestamp":1731316104527,"user_tz":-60,"elapsed":401236,"user":{"displayName":"Mahdi Torkzaban","userId":"15809237820962324254"}},"outputId":"32b59cb0-bd9c-446c-f139-e1db96f00878"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Maximum number of iterations has been exceeded.\n","         Current function value: 0.332582\n","         Iterations: 20000\n","                           Logit Regression Results                           \n","==============================================================================\n","Dep. Variable:                 result   No. Observations:                24088\n","Model:                          Logit   Df Residuals:                    24033\n","Method:                           MLE   Df Model:                           54\n","Date:                Mon, 11 Nov 2024   Pseudo R-squ.:                  0.5154\n","Time:                        09:08:25   Log-Likelihood:                -8011.2\n","converged:                      False   LL-Null:                       -16533.\n","Covariance Type:            nonrobust   LLR p-value:                     0.000\n","==============================================================================\n","                 coef    std err          z      P>|z|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const          0.2563      0.046      5.575      0.000       0.166       0.346\n","x1            -0.1426      0.045     -3.164      0.002      -0.231      -0.054\n","x2            -0.0093      0.028     -0.328      0.743      -0.065       0.046\n","x3            -0.0027      0.026     -0.104      0.917      -0.053       0.048\n","x4            -0.7562      0.082     -9.194      0.000      -0.917      -0.595\n","x5             0.1801      0.093      1.943      0.052      -0.002       0.362\n","x6             0.5288      0.076      6.960      0.000       0.380       0.678\n","x7            -2.8381      0.140    -20.287      0.000      -3.112      -2.564\n","x8            -0.4391      0.070     -6.232      0.000      -0.577      -0.301\n","x9            -0.0441      0.038     -1.162      0.245      -0.119       0.030\n","x10            0.0617      0.069      0.897      0.370      -0.073       0.196\n","x11            0.1176      0.065      1.815      0.069      -0.009       0.245\n","x12            0.0218      0.089      0.247      0.805      -0.152       0.195\n","x13           -0.4814      0.171     -2.817      0.005      -0.816      -0.146\n","x14            0.0726      0.115      0.632      0.527      -0.153       0.298\n","x15           -0.4409      0.133     -3.327      0.001      -0.701      -0.181\n","x16        -6919.6628   5.94e+05     -0.012      0.991   -1.17e+06    1.16e+06\n","x17        -3.692e+04   2.15e+05     -0.171      0.864   -4.59e+05    3.85e+05\n","x18         1.062e+04   1.66e+05      0.064      0.949   -3.15e+05    3.36e+05\n","x19            4.0829      1.875      2.178      0.029       0.408       7.757\n","x20           -0.6017      1.938     -0.310      0.756      -4.400       3.197\n","x21           -8.9298     10.353     -0.863      0.388     -29.221      11.361\n","x22            0.1020      0.053      1.920      0.055      -0.002       0.206\n","x23           -0.0217      0.065     -0.332      0.740      -0.150       0.106\n","x24           -0.0619      0.053     -1.176      0.240      -0.165       0.041\n","x25           -1.0733      0.098    -10.942      0.000      -1.265      -0.881\n","x26            0.1356      0.114      1.185      0.236      -0.089       0.360\n","x27            0.5004      0.117      4.277      0.000       0.271       0.730\n","x28            0.0746      0.077      0.975      0.330      -0.075       0.225\n","x29           -0.1738      0.088     -1.981      0.048      -0.346      -0.002\n","x30            0.1331      0.072      1.859      0.063      -0.007       0.273\n","x31            0.5326      0.108      4.917      0.000       0.320       0.745\n","x32            0.2544      0.132      1.934      0.053      -0.003       0.512\n","x33           -0.6681      0.160     -4.163      0.000      -0.983      -0.354\n","x34            0.0115      0.035      0.331      0.741      -0.057       0.080\n","x35            0.0217      0.025      0.868      0.385      -0.027       0.071\n","x36           -0.0172      0.023     -0.745      0.456      -0.062       0.028\n","x37         3437.2552   2.95e+05      0.012      0.991   -5.75e+05    5.81e+05\n","x38         2.599e+04   1.52e+05      0.171      0.864   -2.71e+05    3.23e+05\n","x39        -8122.2647   1.27e+05     -0.064      0.949   -2.57e+05    2.41e+05\n","x40           -0.2298      0.070     -3.267      0.001      -0.368      -0.092\n","x41            0.2759      0.092      2.995      0.003       0.095       0.456\n","x42           -0.0088      0.074     -0.119      0.905      -0.153       0.136\n","x43        -1260.6928   1.08e+05     -0.012      0.991   -2.13e+05    2.11e+05\n","x44        -9242.9179   5.39e+04     -0.171      0.864   -1.15e+05    9.64e+04\n","x45         2840.7687   4.44e+04      0.064      0.949   -8.41e+04    8.98e+04\n","x46        -6618.6088   5.68e+05     -0.012      0.991   -1.12e+06    1.11e+06\n","x47        -3.448e+04   2.01e+05     -0.171      0.864   -4.29e+05     3.6e+05\n","x48         9775.7897   1.53e+05      0.064      0.949    -2.9e+05    3.09e+05\n","x49           -0.1206      0.075     -1.617      0.106      -0.267       0.026\n","x50            0.0970      0.077      1.266      0.205      -0.053       0.247\n","x51            0.1418      0.057      2.488      0.013       0.030       0.254\n","x52           -1.0188      0.863     -1.180      0.238      -2.711       0.673\n","x53            0.5519      1.212      0.455      0.649      -1.824       2.928\n","x54            5.8678      7.077      0.829      0.407      -8.002      19.738\n","==============================================================================\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Fit logistic regression model with regularization\n","logit_model = LogisticRegression(C=1, penalty='l2', max_iter=20000)  # C is the inverse of regularization strength\n","logit_model.fit(X, y)\n","\n","# Display coefficients\n","print(\"Coefficients:\", logit_model.coef_)\n","print(\"Intercept:\", logit_model.intercept_)\n"],"metadata":{"id":"G_5oORvAzx9V","executionInfo":{"status":"aborted","timestamp":1731315702173,"user_tz":-60,"elapsed":8,"user":{"displayName":"Mahdi Torkzaban","userId":"15809237820962324254"}}},"execution_count":null,"outputs":[]}]}